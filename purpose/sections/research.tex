\section*{Research}
\paragraph{Bayesian Optimization}
Bayesian optimization \cite{Mockus:1974}, an efficient approach to optimizing unknown functions, has been used successfully to optimize designs in aerospace engineering \cite{Lam:Aero}, recommender systems \cite{Li:2010:NewsBandits, ChapelleL11:News, VanchinathanNBK14:recommender}, and machine learning algorithms \cite{bergstra2011algorithms, gelbart2014}. During my time at Oak Ridge National Lab I developed a distributed Bayesian optimization algorithm, \textit{HyperSpace} \cite{Young2018Hyperspace}, to better guide research efforts in machine learning. This algorithm respected early theoretical results in Bayesian optimization that had previously been ignored by the machine learning community, and resulted better modeling performance for both supervised and reinforcement learning problems when compared with other hyperparameter optimization techniques. While improving predictive performance of our algorithms was certainly important, HyperSpace aided a larger goal for our research efforts: helping us to understand how the space of possible algorithm configurations fit our research domain. HyperSpace was designed not to simply find the best configurations of our algorithms, but to show what changes in our algorithms improved performance, and where changes in our algorithms harmed performance. Since machine learning is an inherently iterative process, employing HyperSpace allowed us to better steer our research efforts by giving us a richer perspective on our modeling choices. 

\paragraph{Reinforcement Learning}
Reinforcement learning (RL) is a subfield of machine learning wherein an agent learns to maximize some expected reward by interacting with its environment \cite{Sutton:1998, Recht:Tour}. This form of learning closely resembles human and animal learning in that the agent must make decisions in a dynamic environment of which the agent may only have partial knowledge. There have been several notable recent milestones within the field, including human level mastery of chess, shogi, Go \cite{Silver1140}, and Atari games \cite{Mnih:Atari}. However, RL remains notoriously difficult due in part to RL algorithms' high variance and sensitivity to model hyperparameters \cite{Henderson:RLMatters, MachadoBTVHB18}. My current research explores hyperparameter optimization methods for RL algorithms. This work is intended to give a more thorough presentation of the how susceptible RL algorithms are to model architectures. Currently many baseline implementations of these algorithms must trust the hyperparameter settings found by groups like DeepMind and OpenAi since running hyperparameter optimization in this domain is prohibitively expensive. Since my work with the Hyperspace algorithm makes cataloging model performance across a variety of conditions a priority, I believe that I am uniquely positioned to provide valuable benchmarks for RL algorithms. This information could potentially be carried forward into meta-learning studies for RL and could help us to design algorithms that are not so sensitive to hyperparameters.